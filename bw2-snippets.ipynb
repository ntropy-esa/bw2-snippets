{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bw2-snippets\n",
    "A compilation of code snippets, useful when using brightway2, the python framework for life cycle assessment, especially when starting\n",
    "\n",
    "The code snippets are compiled in a jupyter notebook, and described with markdown text and/or in-line comments. \n",
    "\n",
    "Future to-do:\n",
    "- split in several notebooks, per theme / user level\n",
    "- create a jupyter notebook \"extension\" to access the code snippets directly in jupyter's gui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import common libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from bw2data.parameters import ActivityParameter, DatabaseParameter, ProjectParameter, Group\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select existing or create bw2 project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'my_project_name'\n",
    "if project_name not in bw2.projects:\n",
    "    bw2.projects.create_project(project_name)\n",
    "bw2.projects.set_current(project_name)\n",
    "\n",
    "if \"biosphere3\" not in bw2.databases:\n",
    "    bw2.bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = 'my_project_name'\n",
    "bw2.projects.set_current(pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search for activity in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'use_1_tree-planting' # name of database to search\n",
    "# search via list comprehension\n",
    "act = [a for a in bw2.Database(db_name)\n",
    "       if \"keyword to search\" in str(a)\n",
    "       and not \"keyword to exclude\" in str(a)\n",
    "       # add more keywords to search/exclude by adding lines below:  and \"...\" in str(a)\n",
    "      ] \n",
    "act.sort(reverse=True) # optional sorting of list\n",
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchActivity(ins=[], outs=[], db=''):\n",
    "    '''\n",
    "    Usage:\n",
    "    activities = searchActivity(ins=['lifecycle'], outs=[], db='use_4_filter')\n",
    "    '''\n",
    "    return [a for a in bw2.Database(db)\n",
    "           if all(str_in in str(a) for str_in in ins)\n",
    "           and all(str_out not in str(a) for str_out in outs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchParameters(string):\n",
    "    '''\n",
    "    Search for all parameters containing string in their param.name\n",
    "    For the current project, using ProjectParameter function (get it via: from bw2data.parameters import ProjectParameter \n",
    "    \n",
    "    '''\n",
    "    wanted = []\n",
    "    for param in ProjectParameter.select():\n",
    "        # param.dict = whole dict\n",
    "        # other attributes of param object: database, code, name, formula, amount\n",
    "        if str(string) in param.name:\n",
    "            wanted.append(param.dict)\n",
    "    return wanted\n",
    "\n",
    "def getSingleParam(name, silent=False):\n",
    "    # get individual parameter by name\n",
    "    p = ProjectParameter.get(ProjectParameter.name == name)\n",
    "    if not silent:\n",
    "        print(p.name, p.amount, p.formula)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select IPCC and ILCD methods, create list of units with corrected syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC = [method for method in bw2.methods if \"IPCC 2013\" in str(method) \n",
    "        and \"GWP 100\" in str(method) \n",
    "        and \"LT\" not in str(method)\n",
    "        and \"V1\" not in str(method)]\n",
    "IPCC_unit = [r'kg $CO_2$-eq']\n",
    "\n",
    "EcoScarEnergy = [method for method in bw2.methods\n",
    "        if \"ecological scarcity\" in str(method) \n",
    "        and \"2013\" in str(method)\n",
    "        and \"energy\" in str(method)\n",
    "        and \"no LT\" not in str(method)]\n",
    "\n",
    "EcoScarEnergy_unit = [bw2.methods[method]['unit'] for method in EcoScarEnergy]\n",
    "\n",
    "CExD = [method for method in bw2.methods\n",
    "        if \"cumulative exergy demand\" in str(method) ]\n",
    "CExD_units = [bw2.methods[method]['unit'] for method in CExD]\n",
    "\n",
    "ILCD = [method for method in bw2.methods if \"ILCD 2.0\" in str(method) \n",
    "        and \"LT\" not in str(method)\n",
    "        and \"V1\" not in str(method)\n",
    "        and \"climate change\" not in str(method)] # excluding climate change\n",
    "\n",
    "ILCD_units = [bw2.methods[method]['unit'] for method in ILCD]\n",
    "# correct some units, with chemical symbols\n",
    "ILCD_units[0] = r'mol $H^{+}$-Eq'\n",
    "ILCD_units[6] = r'kg $U_235$-Eq'\n",
    "ILCD_units[-5] = r'$m^3$ water'\n",
    "\n",
    "all_methods= IPCC + ILCD + CExD\n",
    "all_methods_units= IPCC_unit + ILCD_units + CExD_units\n",
    "\n",
    "slt = [0, 4, 14, 15]\n",
    "subset_methods = [all_methods[i] for i in slt]\n",
    "subset_methods_units = [all_methods_units[i] for i in slt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write new data to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = bw2.Database(fg_db) # loads the data existing, the new scenario will be pushed to it\n",
    "data = db.load()\n",
    "data.update( new_activity ) # only update the key (fg_db, act_code) or create it\n",
    "db.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to import LCI of pyrolysis reactor from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reactors_lci(all_reactors):\n",
    "    '''\n",
    "    Parse Inventories from an excel file, and return dictionary\n",
    "    '''\n",
    "    new_activity = {}\n",
    "    fg_db = 'pro_biochar'\n",
    "    fp = 'lci/LCI_pyrolysis reactors.xlsx'\n",
    "\n",
    "    for reactor in all_reactors:\n",
    "        df_lci = pd.read_excel(fp, sheet_name=reactor, usecols='B:G', skiprows=15)\n",
    "\n",
    "        act_code = 'manufdisposal'+reactor\n",
    "\n",
    "        plant_activity = {\n",
    "            'name': 'manufacturing and disposal of pyrolysis reactor '+reactor,\n",
    "            'code': act_code,\n",
    "            'unit': 'unit',\n",
    "            'location':'CH',\n",
    "            'type': 'process',\n",
    "            'reference product': 'pyrolysis reactor, manufactured and disposed, '+reactor,\n",
    "            'comment':'',\n",
    "            'exchanges':[\n",
    "                    {'output': (fg_db, act_code), #self tuple\n",
    "                    'input': (fg_db, act_code), #self tuple\n",
    "                    'type':'production',\n",
    "                    'unit':'unit',\n",
    "                    'amount':1}\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        for index, row in df_lci.iterrows():\n",
    "            key = eval(row['key'])\n",
    "            if key[0] == 'biosphere3':\n",
    "                # add biosphere exchange\n",
    "                plant_activity['exchanges'].append(\n",
    "                    {'type': 'biosphere',\n",
    "                    'name': row['product'],\n",
    "                    'amount': row['amount'],\n",
    "                    'unit': row['unit'],\n",
    "                    'input': eval(row['key']),\n",
    "                    #'negative': row['negative']\n",
    "                    } )\n",
    "\n",
    "            else:\n",
    "                # add technosphere exchange\n",
    "                plant_activity['exchanges'].append(\n",
    "                    {'type': 'technosphere',\n",
    "                    'name': row['activity'],\n",
    "                    'amount': row['amount'],\n",
    "                    'unit': row['unit'],\n",
    "                    'input': eval(row['key']),\n",
    "                    #'negative': row['negative']\n",
    "                    }\n",
    "                )\n",
    "\n",
    "\n",
    "        new_activity.update([ ( (fg_db, act_code), plant_activity) ])\n",
    "\n",
    "    return new_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export / Import Project Parameters between computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw2data.parameters import ActivityParameter, DatabaseParameter, ProjectParameter, Group\n",
    "def ExportProjectParameters(f='ProjectParamExport.xlsx'):\n",
    "    params = { i:p.dict for i,p in enumerate(ProjectParameter.select() )}\n",
    "    pd.DataFrame.from_dict(params).to_excel('ProjectParamExport.xlsx')\n",
    "\n",
    "def LoadProjectParameters(f='ProjectParamExport.xlsx'):\n",
    "    df = pd.read_excel('ProjectParamExport.xlsx', index_col=0)\n",
    "    paramDict = df.to_dict(orient='dict')\n",
    "    paramList = [v for k,v in paramDict.items()]\n",
    "    bw2.parameters.new_project_parameters(paramList, overwrite=True)\n",
    "    bw2.parameters.recalculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverting dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helping functions\n",
    "def rev_dict(d):\n",
    "    '''reverse the k,v of the dictionary'''\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "def reindex_dict(d):\n",
    "    ''' reindexes a dictionary where the keys are integers, sorted'''\n",
    "    return {i:k[1] for i,k in enumerate(d.items())}\n",
    "\n",
    "def readable_dict(d):\n",
    "    ''' d = dict of format key=interger, value=tuple,activity key'''\n",
    "    return {k:bw2.get_activity(v)['name'] for k,v in d.items() }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution analysis - convenient tagging + traverse multiple foreground, with options as in SimaPro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals\n",
    "from eight import *\n",
    "\n",
    "from bw2data import databases, methods, get_activity, Method\n",
    "from bw2calc import LCA\n",
    "from collections import defaultdict\n",
    "\n",
    "def traverse_tagged_databases(\n",
    "    functional_unit, method, label=\"tag\", default_tag=\"other\", secondary_tags=[],\n",
    "    fg_databases=None, bio2tech=False, parent4other=False\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    ESA : allows to perform grouping as in SimaPro \n",
    "    \n",
    "    Traverse a functional unit throughout its foreground database(s) or the \n",
    "    \n",
    "    listed databses in fg_databses, and group impacts by tag label.\n",
    "\n",
    "\n",
    "    Contribution analysis work by linking impacts to individual activities.\n",
    "\n",
    "    However, you also might want to group impacts in other ways. For example,\n",
    "\n",
    "    give individual biosphere exchanges their own grouping, or aggregate two\n",
    "\n",
    "    activities together.\n",
    "\n",
    "\n",
    "    Consider this example system, where the letters are the tag labels, and the\n",
    "\n",
    "    numbers are exchange amounts. The functional unit is one unit of the tree\n",
    "\n",
    "    root.\n",
    "\n",
    "\n",
    "    .. image:: images/tagged-traversal.png\n",
    "\n",
    "       :alt: Example tagged supply chain\n",
    "\n",
    "\n",
    "    In this supply chain, tags are applied to activities and biosphere exchanges.\n",
    "\n",
    "    If a biosphere exchange is not tagged, it inherits the tag of its producing\n",
    "\n",
    "    activity. Similarly, links to other databases are assessed with the usual\n",
    "\n",
    "    LCA machinery, and the total LCA score is tagged according to its consuming\n",
    "\n",
    "    activity. If an activity does not have a tag, a default tag is applied.\n",
    "\n",
    "\n",
    "    We can change our visualization to show the use of the default tags:\n",
    "\n",
    "\n",
    "    .. image:: images/tagged-traversal-2.png\n",
    "\n",
    "       :alt: Example tagged supply chain\n",
    "\n",
    "\n",
    "    And then we can manually calculate the tagged impacts. Normally we would\n",
    "\n",
    "    need to know the actual biosphere flows and their respective\n",
    "\n",
    "    characterization factors (CF), but in this example we assume that each\n",
    "\n",
    "    CF is one. Our result, group by tags, would therefore be:\n",
    "\n",
    "\n",
    "        * **A**: :math:`6 + 27 = 33`\n",
    "\n",
    "        * **B**: :math:`30 + 44 = 74`\n",
    "\n",
    "        * **C**: :math:`5 + 16 + 48 = 69`\n",
    "\n",
    "        * **D**: :math:`14`\n",
    "\n",
    "\n",
    "    This function will only traverse the foreground database, i.e. the\n",
    "\n",
    "    database of the functional unit activity. A functional unit can have\n",
    "\n",
    "    multiple starting nodes; in this case, all foreground databases are\n",
    "\n",
    "    traversed.\n",
    "\n",
    "\n",
    "    Input arguments:\n",
    "\n",
    "        * ``functional_unit``: A functional unit dictionary, e.g. ``{(\"foo\", \"bar\"): 42}``.\n",
    "\n",
    "        * ``method``: A method name, e.g. ``(\"foo\", \"bar\")``\n",
    "\n",
    "        * ``label``: The label of the tag classifier. Default is ``\"tag\"``\n",
    "\n",
    "        * ``default_tag``: The tag classifier to use if none was given. Default is ``\"other\"``\n",
    "\n",
    "        * ``secondary_tags``: List of tuples in the format (secondary_label, secondary_default_tag). Default is empty list.\n",
    "        \n",
    "        * ``fg_databases``: a list of foreground databases to be traversed, e.g. ['foreground', 'biomass', 'machinery']\n",
    "                            It's not recommended to include all databases of a project in the list to be traversed, especially not ecoinvent itself\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "\n",
    "        Aggregated tags dictionary from ``aggregate_tagged_graph``, and tagged supply chain graph from ``recurse_tagged_database``.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    lca = LCA(functional_unit, method)\n",
    "\n",
    "    lca.lci(factorize=True)\n",
    "\n",
    "    lca.lcia()\n",
    "\n",
    "    method_dict = {o[0]: o[1] for o in Method(method).load()}\n",
    "\n",
    "    graph = [\n",
    "        recurse_tagged_database(\n",
    "            key, amount, method_dict, lca, label, default_tag, secondary_tags, fg_databases, parent4other\n",
    "        )\n",
    "        for key, amount in functional_unit.items()\n",
    "    ]\n",
    "\n",
    "    return aggregate_tagged_graph(graph, bio2tech), graph\n",
    "\n",
    "\n",
    "def aggregate_tagged_graph(graph, bio2tech=False,):\n",
    "    \"\"\"Aggregate a graph produced by ``recurse_tagged_database`` by the provided tags.\n",
    "\n",
    "    Outputs a dictionary with keys of tags and numeric values.\n",
    "    \n",
    "    If bio2tech is set to True, then biosphere exchanges are added to the tag of the parent activity (instead of direct emissions)\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        {'a tag': summed LCIA scores}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def recursor(obj, scores):\n",
    "        scores[obj[\"tag\"]] += obj[\"impact\"]\n",
    "        if bio2tech:\n",
    "            for flow in obj[\"biosphere\"]:\n",
    "                scores[obj[\"tag\"]] += flow[\"impact\"]\n",
    "        else: # default behavior\n",
    "            for flow in obj[\"biosphere\"]:\n",
    "                scores[flow[\"tag\"]] += flow[\"impact\"]\n",
    "        for exc in obj[\"technosphere\"]:\n",
    "            scores = recursor(exc, scores)\n",
    "        return scores\n",
    "\n",
    "    scores = defaultdict(int)\n",
    "    for obj in graph:\n",
    "        scores = recursor(obj, scores)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def recurse_tagged_database(\n",
    "    activity, amount, method_dict, lca, label, default_tag, secondary_tags=[], fg_databases=None, parent4other=False\n",
    "):\n",
    "\n",
    "    \"\"\"Traverse a foreground database and assess activities and biosphere flows by tags.\n",
    "\n",
    "\n",
    "    Input arguments:\n",
    "\n",
    "\n",
    "        * ``activity``: Activity tuple or object\n",
    "\n",
    "        * ``amount``: float\n",
    "\n",
    "        * ``method_dict``: Dictionary of biosphere flow tuples to CFs, e.g. ``{(\"biosphere\", \"foo\"): 3}``\n",
    "\n",
    "        * ``lca``: An ``LCA`` object that is already initialized, i.e. has already calculated LCI and LCIA with same method as in ``method_dict``\n",
    "\n",
    "        * ``label``: string\n",
    "\n",
    "        * ``default_tag``: string\n",
    "\n",
    "        * ``secondary_tags``: List of tuples in the format (secondary_label, secondary_default_tag). Default is empty list.\n",
    "        \n",
    "        * ``fg_databases``: a list of foreground databases to be traversed, e.g. ['foreground', 'biomass', 'machinery']\n",
    "                            It's not recommended to include all databases of a project in the list to be traversed, especially not ecoinvent itself\n",
    "\n",
    "        * parent4other=False : if True, untagged technosphere exchanges are aggregated with their parent .. become \"outside\"\n",
    "\n",
    "  Returns:\n",
    "\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "\n",
    "        {\n",
    "\n",
    "            'activity': activity object,\n",
    "\n",
    "            'amount': float,\n",
    "\n",
    "            'tag': string,\n",
    "\n",
    "            'secondary_tags': [list of strings],\n",
    "\n",
    "            'impact': float (impact of inputs from outside foreground database),\n",
    "\n",
    "            'biosphere': [{\n",
    "\n",
    "                'amount': float,\n",
    "\n",
    "                'impact': float,\n",
    "\n",
    "                'tag': string,\n",
    "\n",
    "                'secondary_tags': [list of strings]\n",
    "\n",
    "            }],\n",
    "\n",
    "            'technosphere': [this data structure]\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(activity, tuple):\n",
    "        activity = get_activity(activity)\n",
    "        \n",
    "    if fg_databases == None: # then set the list equal to the database of the functional unit \n",
    "    \n",
    "        fg_databases = [activity['database']] # list, single item\n",
    "    \n",
    "    elif fg_databases == list(bw2.Database(activity['database']).find_graph_dependents()): \n",
    "        # check that the list fg_databases does not include all the databases involved in the FU \n",
    "        # (otherwise, it would mean we are likely to have to recurse through ecoinvent... not funny)\n",
    "        # ideally, should only on first call of recurse_tagged_database\n",
    "        raise Exception('The list of databases to traverse fg_databases should not be equal to the all databases involved in the project. You risk to attempt to traverse a background database like ecoinvent - it would take too much time')\n",
    "\n",
    "    inputs = list(activity.technosphere())\n",
    "    #print('activity', activity['name'])\n",
    "    #print('inputs', inputs)\n",
    "    \n",
    "    production = list(activity.production())\n",
    "    if len(production) == 1:\n",
    "        scale = production[0][\"amount\"]\n",
    "    elif not production:\n",
    "        # Assume production amount of 1\n",
    "        scale = 1\n",
    "    else:\n",
    "        raise ValueError(\"Can't scale by production exchange\")\n",
    "\n",
    "    inside = [exc for exc in inputs if exc[\"input\"][0] in fg_databases] # inside = activities in fg_databases\n",
    "    #print('inside', inside)\n",
    "    \n",
    "    outside = {\n",
    "        exc[\"input\"]: exc[\"amount\"] / scale * amount\n",
    "        for exc in inputs\n",
    "        if exc[\"input\"][0] not in fg_databases ## calculates impacts for activities outside of fg_databases\n",
    "    } # this is a dict of functional units, ready for lca score calculation\n",
    "\n",
    "    if outside:\n",
    "\n",
    "        lca.redo_lcia(outside)\n",
    "\n",
    "        outside_score = lca.score\n",
    "\n",
    "    else:\n",
    "\n",
    "        outside_score = 0\n",
    "\n",
    "    if parent4other:\n",
    "        #if this option is set to True, will change default_tag's value to the tag\n",
    "        # of the parent activity if itself was not empty \n",
    "        if activity.get(label) != None:\n",
    "            default_tag = activity.get(label)\n",
    "    \n",
    "    #print(default_tag)\n",
    "    return {\n",
    "        \"activity\": activity,\n",
    "        \"amount\": amount,\n",
    "        \"tag\": activity.get(label) or default_tag,\n",
    "        \"secondary_tags\": [activity.get(t[0]) or t[1] for t in secondary_tags],\n",
    "        \"impact\": outside_score,\n",
    "        \"biosphere\": [\n",
    "            {\n",
    "                \"amount\": exc[\"amount\"] / scale * amount,\n",
    "                \"impact\": exc[\"amount\"]\n",
    "                / scale\n",
    "                * amount\n",
    "                * method_dict.get(exc[\"input\"], 0),\n",
    "                \"tag\": exc.get(label) or activity.get(label) or default_tag,\n",
    "                \"secondary_tags\": [\n",
    "                    exc.get(t[0]) or activity.get(t[0]) or t[1] for t in secondary_tags\n",
    "                ],\n",
    "            }\n",
    "            for exc in activity.biosphere()\n",
    "        ],\n",
    "        \"technosphere\": [\n",
    "            recurse_tagged_database(\n",
    "                exc.input,\n",
    "                exc[\"amount\"] / scale * amount,\n",
    "                method_dict,\n",
    "                lca,\n",
    "                label,\n",
    "                default_tag,\n",
    "                secondary_tags,\n",
    "                fg_databases,\n",
    "                parent4other\n",
    "            )\n",
    "            for exc in inside\n",
    "        ],\n",
    "    }\n",
    "\n",
    "def rewrite_tagged_database(fg_db_to_tag, new_data):\n",
    "    '''\n",
    "    fg_db_to_dag : name of database to be re-written in bw2\n",
    "    new_data : the newly tagged database\n",
    "    bw2 will raise error if new data does not correspond to target database\n",
    "    '''\n",
    "    val = input(\"Do you want to proceed (Y/N) ? \")\n",
    "    if val != 'Y':\n",
    "        print('Okay, we stop here')\n",
    "    else:\n",
    "        db = bw2.Database(fg_db_to_tag)\n",
    "        db.write(new_data)\n",
    "        \n",
    "        \n",
    "def conveniently_tag_database(fg_db_to_tag = '', label='', ):\n",
    "    '''\n",
    "    Auxiliary function to conveniently assign new tag labels to a foreground database, for group analysis.\n",
    "    Select a forground database to tag, via fg_db_to_tag;\n",
    "    Then define the label name, via label\n",
    "    Returns the tagged database as a new dictionnnary, to be checked, and then re-written in database\n",
    "    \n",
    "    Usage: new_data = conveniently_tag_database('fg_database', 'label_name')\n",
    "    '''\n",
    "    db = bw2.Database(fg_db_to_tag)\n",
    "    data = db.load()\n",
    "    new_data = {}\n",
    "    print('There are %i items to be tagged, one by one' %(len(data)) )\n",
    "    val = input(\"Do you want to proceed (Y/N) ? \")\n",
    "    if val != 'Y':\n",
    "        print('Okay, we stop here')\n",
    "    else:\n",
    "        print(\"Lets proceed! Type 'skip' in order to not tag the given activity\")\n",
    "        for pro_tpl, pro in data.items():\n",
    "            val = input(pro['name'] + \"... to be in the group called... ? \")\n",
    "            \n",
    "            if val == 'skip':\n",
    "                # need to pop the key if it was defined previously\n",
    "                pro.pop(label, 'label was not present')\n",
    "            if val != 'skip':\n",
    "                pro[label] = val\n",
    "            \n",
    "            new_data[pro_tpl] = pro\n",
    "            \n",
    "    return new_data\n",
    "\n",
    "def conveniently_tag_database_v2(fg_db_to_tag = '', label='', ):\n",
    "    '''\n",
    "    Auxiliary function to conveniently assign new tag labels to a foreground database, for group analysis.\n",
    "    Select a forground database to tag, via fg_db_to_tag;\n",
    "    Then define the label name, via label\n",
    "    Then, loop through all activities, and assign directly new attributes, using peewee functions to save\n",
    "\n",
    "    Does not return anything. Changes are directly saved to database. Should avoid running into bugs of re-writing database. \n",
    "    \n",
    "    Usage: conveniently_tag_database('fg_database', 'label_name')\n",
    "    '''\n",
    "    db = bw2.Database(fg_db_to_tag)\n",
    "    print('There are %i items to be tagged, one by one' %(len(db)) )\n",
    "    val = input(\"Do you want to proceed (Y/N) ? \")\n",
    "    n=0\n",
    "    r=0\n",
    "    if val != 'Y':\n",
    "        print('Okay, we stop here')\n",
    "    else:\n",
    "        print(\"Lets proceed! Type 'skip' in order to not tag the given activity or remove existing tag\")\n",
    "        for act in db:\n",
    "            val = input(act['name'] + \"... to be in the group called... ? \")\n",
    "            \n",
    "            if val == 'skip':\n",
    "                # need to pop the key if it was defined previously\n",
    "                act.pop(label, 'label was not present')\n",
    "                r+=1\n",
    "            if val != 'skip':\n",
    "                act[label] = val\n",
    "                n+=1\n",
    "            \n",
    "            act.save() # save back to db\n",
    "    print(\"Number of activities tagged: %i\" %(n))\n",
    "    print(\"Number of activities skipped: %i\" %(r))\n",
    "    \n",
    "    \n",
    "def run_graphTaggedTraversal(fus, methods, methods_units, label, default_tag, fg_dbs, bio2tech=True, parent4other=True):\n",
    "    '''\n",
    "    For a set of functional units, and a set of impact assessment method (but slow)\n",
    "    '''\n",
    "    \n",
    "    result_pds = pd.DataFrame()\n",
    "    for fu in fus:\n",
    "        #lci, lcia\n",
    "        a = bw2.get_activity( list(fu.items())[0][0] ) # tuple of activity\n",
    "        print(a['name'], str(list(fu.items())[0][1]))\n",
    "        scores = []\n",
    "        for n, m in enumerate(methods): # inefficient on methods, should use multi-method version with switch lcia\n",
    "            agg_graph, graph = traverse_tagged_databases(fu, m, \n",
    "                                                         label=label, default_tag=default_tag,\n",
    "                                                         fg_databases=fg_dbs,\n",
    "                                                         bio2tech=bio2tech,\n",
    "                                                         parent4other=parent4other\n",
    "                                                        )\n",
    "\n",
    "            result_pd = pd.DataFrame(agg_graph, index=[0])\n",
    "\n",
    "            result_pd['Impact'] = [m]\n",
    "            result_pd['Units'] = [methods_units[n]]\n",
    "                       \n",
    "            result_pd['FU'] = [ a['name'] ]\n",
    "            result_pd['FU_amount'] = [ str(list(fu.items())[0][1]) ]\n",
    "            # list(fu.items())[0][0]+'-'+str(list(fu.items())[0][1]) \n",
    "\n",
    "            result_pds = result_pds.append(result_pd, sort=False)\n",
    "\n",
    "    result_pds.set_index(['FU','FU_amount', 'Impact', 'Units'], inplace=True)\n",
    "    \n",
    "    return result_pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot contributions barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barv(df, names, xlabel=None, ylabel=None, figsize=(10, 10), colormap='tab20b', width=0.7):\n",
    "    '''\n",
    "    USE:\n",
    "    f, a = barv(sub_tmp, names, \n",
    "                'Biochar supply chain',\n",
    "                r'kg $CO_2$-eq per kg biochar',\n",
    "                (8,8),\n",
    "                'Set2', # https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "                0.6)\n",
    "    '''\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "\n",
    "    df.plot(kind='bar', stacked=True,\n",
    "         colormap=colormap, # viridis Pastel2 Paired tab20c https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html \n",
    "         rot=0,\n",
    "         width=width,\n",
    "         ax=axes)\n",
    "\n",
    "    #axes.set_yticklabels([act_name], fontsize=14)\n",
    "    axes.set_xticklabels(names, fontsize=14)\n",
    "    axes.set_xlabel(xlabel, fontsize=14)\n",
    "    axes.tick_params(axis='x', which='major', labelsize=12)\n",
    "    \n",
    "    axes.set_ylabel(ylabel, fontsize=18)\n",
    "    \n",
    "    axes.legend(fontsize=14, loc='upper left', bbox_to_anchor=(1, 1.))\n",
    "    axes.axhline(c='black')\n",
    "\n",
    "    \n",
    "    total_score = df.sum(axis=1)\n",
    "    axes.plot(np.arange(0,df.shape[0],1), total_score ,'X', color='black', markersize=15)\n",
    "    \n",
    "    fig_handles = (fig, axes)\n",
    "    print(names, total_score)\n",
    "    return fig_handles\n",
    "\n",
    "def barv_toAxes(ax, df, names, xlabel=None, ylabel=None, ticksize=14, colormap='tab20b', width=0.7):\n",
    "    '''\n",
    "    Plot to the axe specified by ax\n",
    "    '''\n",
    "    df.plot(kind='bar', stacked=True,\n",
    "     colormap=colormap, # viridis Pastel2 Paired tab20c https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html \n",
    "     rot=0,\n",
    "     width=width,\n",
    "     ax=ax)\n",
    "\n",
    "    #axes.set_yticklabels([act_name], fontsize=14)\n",
    "    ax.set_xticklabels(names, fontsize=ticksize)\n",
    "    ax.set_xlabel(xlabel, fontsize=14)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=ticksize)\n",
    "    \n",
    "    ax.set_ylabel(ylabel, fontsize=18)\n",
    "    \n",
    "    ax.legend(fontsize=14, loc='upper left', bbox_to_anchor=(1, 1.)).set_visible(False)\n",
    "    ax.axhline(c='black')\n",
    "\n",
    "    total_score = df.sum(axis=1)\n",
    "    ax.plot(np.arange(0,df.shape[0],1), total_score ,'X', color='black', markersize=12)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A class for Algebraic Comparative LCA [MSc Lisa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## IPCC method GWP100\n",
    "IPCC = [method for method in bw2.methods if \"IPCC 2013\" in str(method) \n",
    "        and \"GWP 100\" in str(method) \n",
    "        and \"LT\" not in str(method)\n",
    "        and \"V1\" not in str(method)]\n",
    "IPCC_unit = [r'kg $CO_2$-eq']\n",
    "\n",
    "## Helping functions\n",
    "def rev_dict(d):\n",
    "    '''reverse the k,v of the dictionary'''\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "def reindex_dict(d):\n",
    "    ''' reindexes a dictionary where the keys are integers, sorted'''\n",
    "    return {i:k[1] for i,k in enumerate(d.items())}\n",
    "\n",
    "def readable_dict(d):\n",
    "    ''' d = dict of format key=interger, value=tuple,activity key'''\n",
    "    return {k:bw2.get_activity(v)['name'] for k,v in d.items() }\n",
    "\n",
    "\n",
    "def Y_from_dict(fu, A, A_rows, A_cols):\n",
    "    '''Creates Y vector from fu dictionary, and a square matrix A and its col/row names'''\n",
    "    # build the FU as a sympy vector \n",
    "    Y = SparseMatrix(A.shape[0], 1, 0)\n",
    "    for k, v in A_rows.items():\n",
    "        Y[v, 0] = fu[k] if k in fu else 0\n",
    "    return Y\n",
    "\n",
    "\n",
    "### Class for performing comparative LCA in a streamlined fashion, and with algebraic expressions\n",
    "class CLCA: # CLCA = ComparativeLCA (and not consequential LCA)\n",
    "    \n",
    "    def __init__(self, FunctionalUnits=None, SystemsCompared=None, FinalProducts=None, ImpactCategories=IPCC):\n",
    "        '''\n",
    "        \n",
    "        '''        \n",
    "        self.FunctionalUnits = FunctionalUnits # as list of dictionary \n",
    "        self.SystemsCompared = SystemsCompared # as list of keys\n",
    "        self.FinalProducts = FinalProducts # as list of keys of SOUPs, referring to products \n",
    "        \n",
    "        self.SystemsCompared_Names = { k: bw2.get_activity(k)['name'] for k in self.SystemsCompared }\n",
    "        self.FinalProducts_Names = { k: bw2.get_activity(k)['name'] for k in self.FinalProducts }\n",
    "        \n",
    "        self.ImpactCategories = ImpactCategories\n",
    "        \n",
    "        self.ForegroundDatabase = self.SystemsCompared[0][0]# assuming all activities in the same foreground database\n",
    "        check_fgdb = [self.SystemsCompared[k][0] for k,s in enumerate(self.SystemsCompared)]\n",
    "        if len(set(check_fgdb))>1:\n",
    "            print(\"Systems compared not saved in the same foreground database. Warning - This case is not supported by the matrix generating functions\")\n",
    "        \n",
    "        self.Combinations = None # number of combinations    \n",
    "        self.CombinationsMatrices = {} #empty dictionnary\n",
    "        self.InventoryScores = None \n",
    "        self.ImpactScores = None\n",
    "    \n",
    "    def gen_matrices(self):\n",
    "        '''\n",
    "        Generate a sympy technosphere and biosphere matrices for the foreground + compressed background system\n",
    "        \n",
    "        '''\n",
    "\n",
    "        ## Helping functions\n",
    "        act_symbols = dict()  # Dict of  act = > symbol\n",
    "        def _slugify(str) :\n",
    "            return re.sub('[^0-9a-zA-Z]+', '_', str)\n",
    "\n",
    "        def act_to_symbol(db_name, code):\n",
    "\n",
    "            act = getActByCode(db_name, code)\n",
    "            name = act['name']\n",
    "            base_slug = _slugify(name)\n",
    "\n",
    "            slug = base_slug\n",
    "            i = 1\n",
    "            while symbols(slug) in act_symbols.values():\n",
    "                slug = f\"{base_slug}{i}\"\n",
    "                i += 1\n",
    "\n",
    "            return symbols(slug)\n",
    "\n",
    "        def _getAmountOrFormula(ex):\n",
    "            \"\"\" Return either a fixed float value or an expression for the amount of this exchange\"\"\"\n",
    "            if 'formula' in ex:\n",
    "                try:\n",
    "                    return parse_expr(ex['formula'])\n",
    "                except:\n",
    "                    _eprint(\"Error while parsing formula '%s' : backing to amount\" % ex['formula'])\n",
    "\n",
    "            return ex['amount']\n",
    "\n",
    "        ## Step 1\n",
    "        ## Determine the size of the factorised technosphere A and biosphere B matrices\n",
    "        \n",
    "        ## A = (p + n) x (f + n), where: \n",
    "        ## f = nb of activities in foreground databases, and\n",
    "        ## n = nb of unique bg activities used in foreground database\n",
    "        ## p = nb of unique products genereted by foreground system\n",
    "        \n",
    "        ## B = b x (f + n), where:\n",
    "        ## b = nb of unique direct emissions in foreground system\n",
    "        \n",
    "        fgdb = bw2.Database(self.ForegroundDatabase)\n",
    "        fgdb_data = sorted(fgdb.load().items()) # as a soreted list\n",
    "\n",
    "        f = 0 # number of foreground activities\n",
    "        n = 0 # number of background activities used\n",
    "        p = 0 # number of foreground products\n",
    "        b = 0 # number of direct emissions\n",
    "        list_n = []\n",
    "        list_p = []\n",
    "        list_b = [] \n",
    "        for k, v in fgdb_data: \n",
    "            if \"# asTech\" not in v['name']:\n",
    "                f+=1 # go to next iteration, # we don't want these processes in the matrix\n",
    "            for exch in v['exchanges']:\n",
    "                # encountered a new background input\n",
    "                if exch['input'][0] not in [ self.ForegroundDatabase, 'biosphere3' ] and exch['input'] not in list_n:\n",
    "                    n+=1\n",
    "                    list_n.append(exch['input'])    \n",
    "                # encountered a new product\n",
    "                if exch['input'][0] in [ self.ForegroundDatabase ] and exch['input'] not in list_p:\n",
    "                    p+=1\n",
    "                    list_p.append(exch['input'])   \n",
    "                # encountered a new bioshere emission in by a foreground activity\n",
    "                if exch['input'][0] in [ 'biosphere3'] and exch['input'] not in list_b:\n",
    "                    b+=1\n",
    "                    list_b.append(exch['input']) \n",
    "        \n",
    "        ## initialize sparse matrix, with 0\n",
    "        A = SparseMatrix(p+n, f+n, 0) # Technosphere matrix ... rectangular \n",
    "        B = SparseMatrix(b, f+n, 0) # Biosphere matrix ... rectangular \n",
    "        \n",
    "        ZeroVector = SparseMatrix(p+n,1,0) # A Zero Activity, to check equality to 0 of columns\n",
    "        \n",
    "        ## Step 2\n",
    "        ## Loop on data, to generate matrices expressions\n",
    "        \n",
    "        ## Initialise dictionaries\n",
    "        c = 0 # column counter for A & B\n",
    "        activity_dict = {} # columns of the technosphere matrix A\n",
    "        r = 0 # row counter for A\n",
    "        product_dict = {} # rows of the technosphere matrix A\n",
    "        rb = 0 # row counter for B\n",
    "        biosphere_dict = {} # # rows of the biosphere matrix B\n",
    "\n",
    "        bg_act_needed = {}\n",
    "\n",
    "        ## for loop on all activities from the foreground database\n",
    "        for act_tpl, act_data in fgdb_data:\n",
    "            \n",
    "            activity_dict[act_tpl] = c # activity assigned this c col number\n",
    "            Ac = c # Ac is the pointer for all the coefficients in that column for that loop \n",
    "            \n",
    "            if \"# asTech\" in act_data['name']:\n",
    "                continue # we go to next item\n",
    "\n",
    "            ## for loop on all its exchanges\n",
    "            for exch in act_data['exchanges']:\n",
    "                if exch['type'] == 'biosphere':\n",
    "                ## if exch with biosphere \n",
    "                    if exch['input'] in biosphere_dict:\n",
    "                        Br = biosphere_dict[exch['input']]\n",
    "                    else:\n",
    "                        Br = rb\n",
    "                        biosphere_dict[exch['input']] = Br\n",
    "                        rb+=1\n",
    "                    formula = _getAmountOrFormula(exch)\n",
    "                    B[Br, Ac] = formula\n",
    "\n",
    "                elif exch['input'][0] in [ self.ForegroundDatabase ]: \n",
    "                ## if exch within foreground db:\n",
    "                    sign = +1 if exch['type'] == 'production' else -1\n",
    "                    ## insert coefficient in the sympy sparse matrix, with amount = sympy expression\n",
    "                    formula = _getAmountOrFormula(exch)\n",
    "\n",
    "                    if exch['input'] in product_dict:\n",
    "                        Ar = product_dict[exch['input']]\n",
    "                    else:\n",
    "                        Ar = r\n",
    "                        product_dict[exch['input']] = Ar\n",
    "                        r+=1\n",
    "                    A[Ar, Ac] = sign*formula                    \n",
    "\n",
    "                elif exch['input'][0] not in [ self.ForegroundDatabase, 'biosphere3' ]:\n",
    "                ## if exch in bg db: we have 2 things to do\n",
    "                ## 1) Add a diagonal coefficient for that background activity producing itself\n",
    "                ## 2) Add the non-diagonal coefficient in the column of the current activity !\n",
    "                \n",
    "                    sym = act_to_symbol(exch['input'][0], exch['input'][1])\n",
    "                    ## \n",
    "                    if exch['input'] in product_dict:\n",
    "                        Ar = product_dict[exch['input']]\n",
    "                        formula = _getAmountOrFormula(exch)\n",
    "                        A[Ar, Ac] = -1*formula\n",
    "                        \n",
    "                    else: # we encounter a new activity, which does not yet have a col number\n",
    "                        c = c + 1 # we assign a new number to c for that background activity\n",
    "                        Ar = r # we also assign a new product (though different couting technique-artefact of shitty development)\n",
    "                        r+=1\n",
    "                        product_dict[exch['input']] = Ar\n",
    "                        activity_dict[exch['input']] = c\n",
    "                        A[Ar, c] = 1 # so-called diag coefficient (maybe it's not on the diag)\n",
    "                        \n",
    "                        formula = _getAmountOrFormula(exch)\n",
    "                        A[Ar, Ac] = -1*formula\n",
    "                                        \n",
    "                    bg_act_needed[exch['input']] = sym ## and add background activity to list of activities for which we need EF values (to calc separately in a MultiLCA with many FUs rather than here)\n",
    "\n",
    "            # back in first for loop\n",
    "            c = c + 1 # increase the counter to go to the next activity\n",
    "        \n",
    "        self.A_NS = A\n",
    "        self.A_NS_rows = product_dict\n",
    "        self.A_NS_columns = activity_dict\n",
    "        self.BackgroundActivities = bg_act_needed\n",
    "        self.B_NS = B\n",
    "        self.B_NS_rows = biosphere_dict\n",
    "        \n",
    "        def check_zero_columns(A, A_columns):\n",
    "            '''Check and returns a list of columns equal to 0'''\n",
    "            zeroActivities = {}\n",
    "            for i in range(A.shape[1]): # loop on columns\n",
    "                if A[:,i] == ZeroVector:\n",
    "                    zeroActivities[i] = rev_dict(A_columns)[i]\n",
    "            if len(zeroActivities) > 0:\n",
    "                self.A_NS_Zeros = zeroActivities\n",
    "                raise Exception('Technosphere matrix A_NS has %i activities with null coefficients. The matrix is not invertible... Check data or matrix parser' %(len(zeroActivities)))\n",
    "        check_zero_columns(self.A_NS, self.A_NS_columns)\n",
    "        \n",
    "    def calc_inventories(self):\n",
    "        '''\n",
    "        Loop on all fu, system, and soup combinations...\n",
    "        '''\n",
    "        \n",
    "        def calc_inventory(fu, A, A_col_names):\n",
    "            '''\n",
    "            For a unique given system combination (i.e. S, FU, and closing SOUPs) calculates the inventory\n",
    "            Returns the inventory with indices referring to the ones in the non-square matrix, as sympy vector\n",
    "\n",
    "            '''\n",
    "            # build the FU as a sympy vector \n",
    "            Y = SparseMatrix(A.shape[0], 1, 0)\n",
    "            for k, v in self.A_NS_rows.items():\n",
    "                Y[v, 0] = fu[k] if k in fu else 0\n",
    "            # this will only give the solution as in \"amount\" of each activity needed?\n",
    "            X = A.inv(method='GE')*Y\n",
    "            \n",
    "            # X conversion to other row indices, with 0 whenever relevant\n",
    "            \n",
    "            # mapping from A_col_names to A_NS_col_names: one dictionary is larger than the other\n",
    "            mapping = {col_A : self.A_NS_columns[name] for name, col_A  in A_col_names.items() }\n",
    "    #        for name, col_A  in A_col_names.items():\n",
    "     #           mapping[col_A] = self.A_NS_columns[name]\n",
    "            X_NS = SparseMatrix(self.A_NS.shape[1], 1, 0)\n",
    "            for i,j in mapping.items():\n",
    "                X_NS[j,0] = X[i,0] \n",
    "            \n",
    "            return X, A_col_names, X_NS\n",
    "        \n",
    "        def squared_matrix(fu, sys, all_products, set_system, set_fu, diff1, diff2, cb):\n",
    "            ''' \n",
    "            Generates the square sympy matrix\n",
    "            '''\n",
    "            \n",
    "            A = self.A_NS.copy()\n",
    "            A_col_names = self.A_NS_columns\n",
    "            A_row_names = self.A_NS_rows\n",
    "\n",
    "            rev_A_col_names = rev_dict(A_col_names)\n",
    "            rev_A_row_names = rev_dict(A_row_names)            \n",
    "            \n",
    "            # non-studied systems right now\n",
    "            systems_to_remove = [A_col_names[s] for s in self.SystemsCompared if s != sys]  # list of column nbrs to remove\n",
    "            \n",
    "            # combinations of closing systems\n",
    "            to_remove = all_products.difference(diff1).difference(diff2).difference(cb)\n",
    "            soups_to_remove = [A_col_names[s] for s in to_remove ]\n",
    "            \n",
    "            # all columns to remove\n",
    "            columns_to_remove = systems_to_remove + soups_to_remove # list concatenation\n",
    "            columns_to_remove.sort() # inplace sorting of list items\n",
    "            \n",
    "            off=0\n",
    "            for c in columns_to_remove:\n",
    "                A.col_del(c-off) # column deleted,\n",
    "                off += 1 # offset in column number\n",
    "                rev_A_col_names.pop(c)\n",
    "                \n",
    "            rev_A_col_names = reindex_dict(rev_A_col_names) #reindexing col\n",
    "            new_A_col_names = rev_dict(rev_A_col_names)\n",
    "            \n",
    "            return A, new_A_col_names, rev_A_col_names\n",
    "        \n",
    "        def SystemCombinations(fu, sys):\n",
    "            '''\n",
    "            Calculate nb of system combinations for a given fu and sys\n",
    "            '''\n",
    "            s = bw2.get_activity(sys)\n",
    "            set_system = [] # an empty set\n",
    "            for e in s.exchanges():\n",
    "                if e['type'] == 'production':\n",
    "                    set_system.append(e['input'])\n",
    "                if e['type'] == 'technosphere' and e['amount']<0:\n",
    "                    set_system.append(e['input'])\n",
    "            set_system = set(set_system)\n",
    "\n",
    "            set_fu = [ f for f in fu.keys() ] # list comprehensions\n",
    "            set_fu = set(set_fu)\n",
    "\n",
    "            all_products = set_fu.union(set_system)\n",
    "            diff1 = set_fu.difference(set_system) # products that are demanded by the FU but not produced in the scenario            \n",
    "            diff2 = set_system.difference(set_fu) # products not demanded in the FU and produced in the scenario\n",
    "            d = set_system.intersection(set_fu) # intersection of both FU and system\n",
    "            e = len(set_fu)- len(diff1) - 1   # \n",
    "            if e>0: \n",
    "                # there are several combinations possible\n",
    "                combi = list(itertools.combinations(d, e))\n",
    "                n_combi = len(combi)\n",
    "            else:\n",
    "                combi = []\n",
    "                n_combi = 1\n",
    "            \n",
    "            return n_combi, all_products, set_system, set_fu, diff1, diff2, combi\n",
    "        \n",
    "        \n",
    "        ## Step 1\n",
    "        i = 0\n",
    "        for fu in self.FunctionalUnits: # first loop on FU, because we make comparisons between systems for the same FU\n",
    "            for sys in self.SystemsCompared:\n",
    "                # calculate how many soup combinations are possible in that specific case\n",
    "                n_combi, all_products, set_system, set_fu, diff1, diff2, combi = SystemCombinations(fu, sys)\n",
    "                \n",
    "                if n_combi < 2:\n",
    "                    i+=1\n",
    "                    ## call inventory calculation for defined system\n",
    "                    A, A_col_names, A_rev_col_names = squared_matrix(fu, sys, all_products, set_system, set_fu, diff1, diff2, set() )\n",
    "                    self.CombinationsMatrices[i] =  {'fu': fu,\n",
    "                                                     'system':sys,\n",
    "                                                     'combi': 'unique',\n",
    "                                                     'A': A,\n",
    "                                                     'A_col_names': A_col_names,\n",
    "                                                     'A_rev_col_names': A_rev_col_names\n",
    "                                                    }\n",
    "                    X, X_col_names, X_NS = calc_inventory(fu, A, A_col_names)\n",
    "                    self.CombinationsMatrices[i]['X'] = X\n",
    "                    self.CombinationsMatrices[i]['X_NS'] = X_NS\n",
    "\n",
    "                else:\n",
    "                    for cb in combi:\n",
    "                        i+=1\n",
    "                        ## call inventory calculation for defined system\n",
    "                        A, A_col_names, A_rev_col_names = squared_matrix(fu, sys, all_products, set_system, set_fu, diff1, diff2, cb)\n",
    "                        self.CombinationsMatrices[i] =  {'fu': fu,\n",
    "                                                         'system':sys,\n",
    "                                                         'combi': 'multiple',\n",
    "                                                         'A': A,\n",
    "                                                         'A_col_names': A_col_names,\n",
    "                                                         'A_rev_col_names': A_rev_col_names\n",
    "                                                        }\n",
    "                        X, X_col_names, X_NS = calc_inventory(fu, A, A_col_names)\n",
    "                        self.CombinationsMatrices[i]['X'] = X\n",
    "                        self.CombinationsMatrices[i]['X_NS'] = X_NS\n",
    "                        \n",
    "        self.Combinations = i\n",
    "        \n",
    "    def calc_ImpactEquation(self, custom_symbols=None, highlited_foreground=None):\n",
    "        '''\n",
    "        Generic impact equation\n",
    "        \n",
    "        highlited_foreground : a list of activities that we want to use to express the generic impact equation, if present in the matrix,\n",
    "        the results are projected on these activities - can be used to exihbit some parameters, and hide some background details\n",
    "            ## check section 3.1 for implementation\n",
    "        '''\n",
    "        \n",
    "        ## Step 1\n",
    "        ## Assign EF symbols for each activity in foreground (if it has direct emissions) and background\n",
    "        EFs = Matrix( [ symbols('EF_'+str(i)) for i,x in enumerate(self.A_NS_columns) ] )\n",
    "        \n",
    "        ## Step 1.5 Check if the given process has any direct emissions, if not, we can also skip that EF and set it to 0\n",
    "        def checkZero(B, B_col_names):\n",
    "            '''Check if some columns have only 0'''\n",
    "            ZeroVector = SparseMatrix(B.shape[0], 1, 0)\n",
    "            isZero = {}\n",
    "            for i in range(B.shape[1]):\n",
    "                if B[:,i] == ZeroVector:\n",
    "                    isZero[i] = rev_dict(B_col_names)[i]\n",
    "            \n",
    "            return isZero\n",
    "        \n",
    "        isZero = checkZero(self.B_NS, self.A_NS_columns) # B has same columns as A\n",
    "        toSubs = {'EF_'+str(k):0 for k,v in isZero.items() if v[0] in ['MyThesis'] }\n",
    "        EFs = EFs.subs(toSubs)\n",
    "        \n",
    "        ## Step 2\n",
    "        ## Loop on all combinations, and save equation\n",
    "        for c in self.CombinationsMatrices.keys():\n",
    "            X_NS = self.CombinationsMatrices[c]['X_NS']\n",
    "            S_NS = EFs.T*X_NS\n",
    "            self.CombinationsMatrices[c]['S_NS'] = S_NS[0]\n",
    "\n",
    "    def calc_specificImpact(self, reLoadParams=False):\n",
    "        '''Here, the background is actually calculated for the given impact categories !'''\n",
    "        \n",
    "        EFs = SparseMatrix(len(self.ImpactCategories), self.A_NS.shape[1], 0) # as many columns as activities, as many rows as impact categories\n",
    "        \n",
    "        methods = self.ImpactCategories # a list of impact categories\n",
    "        bg_act_fu = [ {bg:1} for bg in self.BackgroundActivities.keys()]\n",
    "        ## for each combination\n",
    "            ## we have the inventory\n",
    "            \n",
    "        ## for each method\n",
    "        ## calc background impacts\n",
    "        def _multiLCA(activities, methods):\n",
    "            \"\"\"Simple wrapper around brightway API\"\"\"\n",
    "            bw2.calculation_setups['process'] = {'inv': activities, 'ia': methods}\n",
    "            lca = bw2.MultiLCA('process')\n",
    "            \n",
    "            cols = [act for act_amount in activities for act, amount in act_amount.items()]\n",
    "            return pd.DataFrame(lca.results.T, index=[method_name(method) for method in methods], columns=cols)\n",
    "\n",
    "        bg_lca = _multiLCA(bg_act_fu, methods) # returns a df\n",
    "        # convert df to a nice useable dictionary here         \n",
    "        bg_scores = {}\n",
    "        for imethod, method in enumerate(methods) :\n",
    "            for iact, act in enumerate(bg_act_fu) :\n",
    "                col = self.A_NS_columns[list(act)[0]]\n",
    "                bg_scores[(col, list(act)[0], method)] = bg_lca.iloc[imethod, iact]\n",
    "                \n",
    "                EFs[imethod, col] = bg_lca.iloc[imethod, iact]\n",
    "                \n",
    "        self.BackgroundActivitiesScores = bg_scores\n",
    "        \n",
    "        ## calc foreground direct emissions  \n",
    "        def _getAmountOrFormula(ex):\n",
    "            \"\"\" Return either a fixed float value or an expression for the amount of this exchange\"\"\"\n",
    "            if 'formula' in ex:\n",
    "                try:\n",
    "                    return parse_expr(ex['formula'])\n",
    "                except:\n",
    "                    _eprint(\"Error while parsing formula '%s' : backing to amount\" % ex['formula'])\n",
    "\n",
    "            return ex['amount']        \n",
    "        def directEmissionsFromAct(act):\n",
    "            '''Creates new activities, in a separate database, with the \n",
    "            direct biosphere emissions of a foreground activities\n",
    "            OBS: the database named DirectEmissions must exist in the project'''\n",
    "            dbname = act[0]\n",
    "            code = act[1]\n",
    "            a = getActByCode(dbname, code)\n",
    "            bioExchanges = {}\n",
    "            for exc in a.exchanges():  \n",
    "                if exc['input'][0] == BIOSPHERE3_DB_NAME :\n",
    "                    bioAct = getActByCode(BIOSPHERE3_DB_NAME, exc['input'][1])#_getDb(BIOSPHERE3_DB_NAME).get()\n",
    "                    if bioAct not in bioExchanges: # in case the same biosphere exchange appears more than once\n",
    "                        bioExchanges[bioAct] = _getAmountOrFormula(exc)\n",
    "                    else:\n",
    "                        bioExchanges[bioAct] += _getAmountOrFormula(exc) \n",
    "            name = a['name']+' #DirectEmissions'\n",
    "            code_to_find = code+'#DirectEmissions'\n",
    "            res = newActivity('DirectEmissions', name, 'unit', bioExchanges, code=code_to_find)\n",
    "            return res\n",
    "\n",
    "        def checkNotZero(B, B_col_names):\n",
    "            '''Check if some columns have only 0'''\n",
    "            ZeroVector = SparseMatrix(B.shape[0], 1, 0)\n",
    "            notZero = {}\n",
    "            noSymbols = {}\n",
    "            hasSymbols = {}\n",
    "            for i in range(B.shape[1]):\n",
    "                if B[:,i] != ZeroVector:\n",
    "                    notZero[i] = rev_dict(B_col_names)[i]\n",
    "                    if len(B[:,i].free_symbols) == 0:\n",
    "                        noSymbols[i] = rev_dict(B_col_names)[i]\n",
    "                    else:\n",
    "                        hasSymbols[i] = rev_dict(B_col_names)[i]\n",
    "\n",
    "            return notZero, noSymbols, hasSymbols\n",
    "        notZero, noSymbol, hasSymbol = checkNotZero(self.B_NS, self.A_NS_columns) # B has same columns as A\n",
    "        # dict, col: key\n",
    "        \n",
    "        ## no symbol\n",
    "        noSymbolDE = {}\n",
    "        for k,v in noSymbol.items(): # k = col number, v = activity code\n",
    "             noSymbolDE[k] = directEmissionsFromAct(v)\n",
    "        fg_act_fu = [ {fg.key:1} for fg in noSymbolDE.values()]\n",
    "        fg_lca = _multiLCA(fg_act_fu, methods) # returns a df\n",
    "        \n",
    "        # convert df to a nice useable dictionary here         \n",
    "        fg_scores = {}\n",
    "        for imethod, method in enumerate(methods) :\n",
    "            for iact, act in enumerate(fg_act_fu) :\n",
    "                key_in_DEdb = list(act)[0]\n",
    "                cd = key_in_DEdb[1].replace('#DirectEmissions', '') # remove the extra tag\n",
    "                key_in_FGdb = tuple((self.ForegroundDatabase, k1))\n",
    "                col = self.A_NS_columns[ key_in_FGdb ]\n",
    "                fg_scores[(col, key_in_FGdb, method)] = fg_lca.iloc[imethod, iact]\n",
    "                EFs[imethod, col] = fg_lca.iloc[imethod, iact]\n",
    "\n",
    "        self.EFs = EFs \n",
    "\n",
    "        ## has symbols\n",
    "        print('There are %i activities with direct emissions with formulas in biosphere exchange. Functionality not yet supported. 0 instead..' %(len(hasSymbol)) )\n",
    "            \n",
    "            \n",
    "        ## save expression for each impact\n",
    "        \n",
    "        if reLoadParams:\n",
    "            loadParams() # re-load lca-algebraic parameters from AB-dev\n",
    "        \n",
    "        \n",
    "                \n",
    "        ## Loop on all combinations, and save impact equation & lambdas\n",
    "        for c in self.CombinationsMatrices.keys():\n",
    "            X_NS = self.CombinationsMatrices[c]['X_NS']\n",
    "            iS_NS = EFs*X_NS\n",
    "            self.CombinationsMatrices[c]['iS_NS'] = iS_NS\n",
    "            ## lambdify expression, ready lca_algebraic.stats functions\n",
    "            self.CombinationsMatrices[c]['lambdas'] = {}\n",
    "            for i in range(iS_NS.shape[0]):\n",
    "                \n",
    "                # in-use symbols\n",
    "                expr = iS_NS[i,:][0]\n",
    "                expr_symbols = [str(k) for k in expr.free_symbols]\n",
    "                params_in_use = {k:v for k,v in lca._param_registry().items() if k in expr_symbols}\n",
    "                self.CombinationsMatrices[c]['lambdas'][i] = lca.LambdaWithParamNames(expr, expanded_params=None, params=params_in_use, sobols=None)\n",
    "\n",
    "## End of the class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Managing sympy expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Append df to existing Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=True, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    Parameters:\n",
    "      filename : File path or existing ExcelWriter\n",
    "                 (Example: '/path/to/file.xlsx')\n",
    "      df : dataframe to save to workbook\n",
    "      sheet_name : Name of sheet which will contain DataFrame.\n",
    "                   (default: 'Sheet1')\n",
    "      startrow : upper left cell row to dump data frame.\n",
    "                 Per default (startrow=None) calculate the last row\n",
    "                 in the existing DF and write to the next row...\n",
    "      truncate_sheet : truncate (remove and recreate) [sheet_name]\n",
    "                       before writing DataFrame to Excel file\n",
    "      to_excel_kwargs : arguments which will be passed to `DataFrame.to_excel()`\n",
    "                        [can be dictionary]\n",
    "\n",
    "    Returns: None\n",
    "\n",
    "    (c) [MaxU](https://stackoverflow.com/users/5741205/maxu?tab=profile)\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    # Python 2.x: define [FileNotFoundError] exception if it doesn't exist \n",
    "    try:\n",
    "        FileNotFoundError\n",
    "    except NameError:\n",
    "        FileNotFoundError = IOError\n",
    "\n",
    "\n",
    "    try:\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook(filename)\n",
    "        \n",
    "        # get the last row in the existing Excel sheet\n",
    "        # if it was not specified explicitly\n",
    "        if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "            startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "        # truncate sheet\n",
    "        if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "            # re-set startrow\n",
    "            startrow=0\n",
    "            # index of [sheet_name] sheet\n",
    "            idx = writer.book.sheetnames.index(sheet_name)\n",
    "            # remove [sheet_name]\n",
    "            writer.book.remove(writer.book.worksheets[idx])\n",
    "            # create an empty sheet [sheet_name] using old index\n",
    "            writer.book.create_sheet(sheet_name, idx)\n",
    "        \n",
    "        # copy existing sheets\n",
    "        writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    except FileNotFoundError:\n",
    "        # file does not exist yet, we will create it\n",
    "        pass\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Temporalis - Helper function to make np.arrays of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from list of values a, list of periods T, list of durations D, construct a curve of periodic inputs\n",
    "def lci_t(list_A, list_T, list_D):\n",
    "    '''\n",
    "    Helper function to create time series of different kinds\n",
    "    Values from A are repeated at the periods in T for the duration in D\n",
    "    The three lists A, T and D must always have the same lenght.\n",
    "    \n",
    "    Example: A = [1], T = [1], D =[20] means 1 is repeated every year for 20 years\n",
    "    Example: A = [1,2], T =[1,3], D = [10, 6] means 1 repeated every year for 10 years, and then 2 repeated every third year for 6 years\n",
    "    \n",
    "    Outputs can be combined..\n",
    "        call 1: A = [2], T = [2], D =[20]\n",
    "        call 2: A = [0,1], T = [1,2], D =[1, 19]\n",
    "        then, sum values of call 1 and 2, and you should get an alternance of 2 and 1 for 20 values\n",
    "    \n",
    "    '''\n",
    "    S = []\n",
    "    for A, T, D in zip(list_A, list_T, list_D):\n",
    "        frag = np.zeros(D)\n",
    "        i = 0\n",
    "        while i < D:\n",
    "            frag[i]=A\n",
    "            i = i + T\n",
    "        S.append(frag)\n",
    "    values = np.concatenate(S, axis=0)\n",
    "    times = np.array([int(d) for d in np.arange(len(values))], dtype='timedelta64[Y]')\n",
    "    total = values.sum()\n",
    "    return values, times, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6, 323.6,\n",
       "       323.6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_applied = [0 for x in range(0,99) ]\n",
    "N_applied = list(np.zeros(100))\n",
    "N_applied\n",
    "\n",
    "precip = np.repeat(323.6, 100)\n",
    "precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 every second year for 10 years\n",
      "times:  [0 1 2 3 4 5 6 7 8 9]\n",
      "values:  [5. 0. 5. 0. 5. 0. 5. 0. 5. 0.]\n",
      "total:  25.0\n",
      "\n",
      "5 every second year for 10 years, and then 2 every third year for 6 years\n",
      "times:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "values:  [5. 0. 5. 0. 5. 0. 5. 0. 5. 0. 2. 0. 0. 2. 0. 0.]\n",
      "total:  29.0\n",
      "\n",
      "alternance of 2 and 1 for 10 years\n",
      "values:  [2. 1. 2. 1. 2. 1. 2. 1. 2. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 16 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD4CAYAAAAn3bdmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMHUlEQVR4nO3cb6zdB13H8ffHdvzZwGzYC+K6etHAFBdgy3WiUyIFTdmWzQc+GBGyREwTAzoMiluWmPBsUYP4wKjNNru4OUJgQzICbgEGIZHh7djmRodMrKMw7V0IMjQBCl8fnNNxd3u682t3zz3nC+9XcnP//e7pZ7ftu+f+zvktVYUkqYcfmfcASdJwRluSGjHaktSI0ZakRoy2JDWyfRY3umPHjlpeXp7FTUvSD6QDBw48XlVL046bSbSXl5dZXV2dxU1L0g+kJP855DhPj0hSI0Zbkhox2pLUiNGWpEaMtiQ1YrQlqZFBT/lLcgh4AvgucLSqVmY5SpI02ck8T/u1VfX4zJZIkqby9IgkNTL0nnYBdyYp4G+rat/GA5LsBfYC7Nq165QHLV/94VP+2kPXXXLKXzvNM9kFi7ttUXfB4m6b5S5pmqH3tC+qqguANwBvTfKajQdU1b6qWqmqlaWlqZfPS5JOwaBoV9VXx6+PALcDF85ylCRpsqnRTnJGkucfexv4deDBWQ+TJB1vyDntFwG3Jzl2/D9U1UdnukqSNNHUaFfVl4BXbsEWSdIUPuVPkhox2pLUiNGWpEaMtiQ1YrQlqRGjLUmNGG1JasRoS1IjRluSGjHaktSI0ZakRoy2JDVitCWpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI0Zbkhox2pLUiNGWpEaMtiQ1YrQlqRGjLUmNGG1JasRoS1Ijg6OdZFuSzyW5Y5aDJEkndjL3tK8CDs5qiCRpukHRTrITuAS4frZzJElPZ+g97fcA7wS+d6IDkuxNsppkdW1tbTO2SZI2mBrtJJcCR6rqwNMdV1X7qmqlqlaWlpY2baAk6fuG3NO+CLgsySHgvcDuJDfPdJUkaaKp0a6qa6pqZ1UtA1cAH6+qN818mSTpOD5PW5Ia2X4yB1fV3cDdM1kiSZrKe9qS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI0Zbkhox2pLUiNGWpEaMtiQ1YrQlqRGjLUmNGG1JasRoS1IjRluSGjHaktSI0ZakRoy2JDVitCWpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI0ZbkhqZGu0kz0ny2ST3J3koybu2Ypgk6XjbBxzzLWB3VX0zyWnAp5N8pKo+M+NtkqQNpka7qgr45vjd08YvNctRkqTJBp3TTrItyX3AEeCuqrpnpqskSRMNinZVfbeqXgXsBC5Mct7GY5LsTbKaZHVtbW2TZ0qS4CSfPVJVXwfuBvZM+Ny+qlqpqpWlpaXNWSdJeoohzx5ZSnLm+O3nAq8HHp7xLknSBEOePfJi4KYk2xhF/n1VdcdsZ0mSJhny7JEHgPO3YIskaQqviJSkRoy2JDVitCWpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI0Zbkhox2pLUiNGWpEaMtiQ1YrQlqRGjLUmNGG1JasRoS1IjRluSGjHaktSI0ZakRoy2JDVitCWpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGpkY7yTlJPpHkYJKHkly1FcMkScfbPuCYo8A7qureJM8HDiS5q6o+P+NtkqQNpt7TrqrHqure8dtPAAeBs2c9TJJ0vCH3tJ+UZBk4H7hnwuf2AnsBdu3atRnbpB86y1d/+Bl9/aHrLtmkJbP1w/LfOQuDH4hM8jzgA8Dbq+obGz9fVfuqaqWqVpaWljZzoyRpbFC0k5zGKNi3VNVts50kSTqRIc8eCXADcLCq3j37SZKkExlyT/si4M3A7iT3jV8unvEuSdIEUx+IrKpPA9mCLZKkKbwiUpIaMdqS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI0Zbkhox2pLUiNGWpEaMtiQ1YrQlqRGjLUmNGG1JasRoS1IjRluSGjHaktSI0ZakRoy2JDVitCWpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI1OjneTGJEeSPLgVgyRJJzbknvZ+YM+Md0iSBpga7ar6FPC1LdgiSZpi085pJ9mbZDXJ6tra2mbdrCRpnU2LdlXtq6qVqlpZWlrarJuVJK3js0ckqRGjLUmNDHnK363APwPnJjmc5C2znyVJmmT7tAOq6o1bMUSSNJ2nRySpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGjLYkNWK0JakRoy1JjRhtSWrEaEtSI0Zbkhox2pLUiNGWpEaMtiQ1YrQlqRGjLUmNGG1JasRoS1IjRluSGjHaktSI0ZakRoy2JDVitCWpEaMtSY0YbUlqxGhLUiNGW5IaMdqS1IjRlqRGjLYkNWK0JamRQdFOsifJF5I8kuTqWY+SJE02NdpJtgF/BbwBeDnwxiQvn/UwSdLxhtzTvhB4pKq+VFXfBt4LXD7bWZKkSVJVT39A8pvAnqr6nfH7bwZ+oaretuG4vcDe8bvnAl/Y/LnsAB6fwe1uBredvEXdBYu7bVF3weJuW9Rd8NRtP1lVS9O+YPuAG82Ejx1X+qraB+wbcHunLMlqVa3M8tc4VW47eYu6CxZ326LugsXdtqi74NS2DTk9chg4Z937O4GvnswvIknaHEOi/S/AS5O8JMmzgCuAD812liRpkqmnR6rqaJK3Af8EbANurKqHZr5sspmefnmG3HbyFnUXLO62Rd0Fi7ttUXfBKWyb+kCkJGlxeEWkJDVitCWpkTbRXtRL6ZOck+QTSQ4meSjJVfPetF6SbUk+l+SOeW9ZL8mZSd6f5OHx9+4X570JIMkfjH8fH0xya5LnzHHLjUmOJHlw3cdekOSuJF8cvz5rQXb92fj38oEktyc5c6t3nWjbus/9YZJKsmNRdiX5vXHXHkryp0Nuq0W0F/xS+qPAO6rqZ4FXA29doG0AVwEH5z1igr8EPlpVPwO8kgXYmORs4PeBlao6j9ED71fMcdJ+YM+Gj10NfKyqXgp8bPz+VtvP8bvuAs6rqlcA/wZcs9WjxvZz/DaSnAP8GvDoVg8a28+GXUley+jq8ldU1c8Bfz7khlpEmwW+lL6qHquqe8dvP8EoPmfPd9VIkp3AJcD1896yXpIfBV4D3ABQVd+uqq/PddT3bQeem2Q7cDpzvCahqj4FfG3Dhy8Hbhq/fRPwG1u5CSbvqqo7q+ro+N3PMLqeY8ud4HsG8BfAO5lwYeBWOMGu3wWuq6pvjY85MuS2ukT7bODL694/zIKEcb0ky8D5wD1znnLMexj9Qf3enHds9FPAGvB341M31yc5Y96jquorjO7tPAo8BvxPVd0531XHeVFVPQajOwzAC+e8Z5LfBj4y7xHHJLkM+EpV3T/vLRu8DPiVJPck+WSSnx/yRV2iPehS+nlK8jzgA8Dbq+obC7DnUuBIVR2Y95YJtgMXAH9dVecD/8t8fsx/ivH54cuBlwA/AZyR5E3zXdVLkmsZnTK8Zd5bAJKcDlwL/Mm8t0ywHTiL0WnVPwLel2RS656iS7QX+lL6JKcxCvYtVXXbvPeMXQRcluQQo9NJu5PcPN9JTzoMHK6qYz+RvJ9RxOft9cB/VNVaVX0HuA34pTlv2ui/k7wYYPx60I/UWyHJlcClwG/V4lwA8tOM/hG+f/x3YSdwb5Ifn+uqkcPAbTXyWUY/EU99kLRLtBf2Uvrxv4w3AAer6t3z3nNMVV1TVTurapnR9+vjVbUQ9xqr6r+ALyc5d/yh1wGfn+OkYx4FXp3k9PHv6+tYgAdIN/gQcOX47SuBf5zjlicl2QP8MXBZVf3fvPccU1X/WlUvrKrl8d+Fw8AF4z+D8/ZBYDdAkpcBz2LI/42wqlq8ABczelT634Fr571n3a5fZnSq5gHgvvHLxfPetWHjrwJ3zHvHhk2vAlbH37cPAmfNe9N417uAh4EHgb8Hnj3HLbcyOrf+HUaxeQvwY4yeNfLF8esXLMiuRxg97nTs78DfLMr3bMPnDwE7FmHXONI3j/+s3QvsHnJbXsYuSY10OT0iScJoS1IrRluSGjHaktSI0ZakRoy2JDVitCWpkf8HHR12T1m9Cm8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## EXAMPLES\n",
    "\n",
    "## 5 every second year for 10 years \n",
    "values, times, total = lci_t(list_A=[5], list_T=[2], list_D=[10])\n",
    "print('5 every second year for 10 years')\n",
    "print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')\n",
    "\n",
    "## 5 every second year for 10 years, and then 2 every third year for 6 years\n",
    "values, times, total = lci_t(list_A=[5,2], list_T=[2,3], list_D=[10,6])\n",
    "print('5 every second year for 10 years, and then 2 every third year for 6 years')\n",
    "print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')\n",
    "\n",
    "## two calls combined, for an alternance of values\n",
    "values1, times, total1 = lci_t(list_A=[2], list_T=[2], list_D=[10])\n",
    "values2, times, total2 = lci_t(list_A=[0,1], list_T=[1,2], list_D=[1,9])\n",
    "values3 = values1 + values2\n",
    "print('alternance of 2 and 1 for 10 years')\n",
    "print('values: ', values3)\n",
    "\n",
    "\n",
    "plt.bar(height=values, x = np.array([int(d) for d in np.arange(len(values))]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round-up, kg/ha/yr\n",
      "times:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100]\n",
      "values:  [2.43 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.43 0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   2.43 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   2.43 0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   2.43]\n",
      "total:  12.15\n",
      "\n",
      "round-up spraying, MJ/ha/yr\n",
      "values:  [28.11  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.   28.11  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.   28.11  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   28.11  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.   28.11]\n",
      "total:  140.55\n",
      "\n",
      "cougar, kg/ha/yr\n",
      "values:  [0.  0.6 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.6 0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.6 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.6 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "total:  2.4\n",
      "\n",
      "cougar spraying, MJ/ha/yr\n",
      "values:  [ 0.   28.11  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.   28.11  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   28.11  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.   28.11  0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.  ]\n",
      "total:  112.44\n",
      "\n",
      "weed harvning, MJ/ha/yr\n",
      "values:  [  0.   843.16   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.   843.16   0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.   843.16   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.   843.16   0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.  ]\n",
      "total:  3372.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#round-up, kg/ha/yr\n",
    "values, times, total = lci_t(list_A=[2.43], list_T=[25], list_D=[101])\n",
    "print('round-up, kg/ha/yr')\n",
    "print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')\n",
    "\n",
    "#round-up spraying, MJ/ha/yr\n",
    "values, times, total = lci_t(list_A=[28.11], list_T=[25], list_D=[101])\n",
    "print('round-up spraying, MJ/ha/yr')\n",
    "#print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')\n",
    "\n",
    "#cougar, kg/ha/yr\n",
    "values, times, total = lci_t(list_A=[0, 0.6], list_T=[1, 25], list_D=[1, 100])\n",
    "print('cougar, kg/ha/yr')\n",
    "#print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')\n",
    "\n",
    "#cougar spraying, MJ/ha/yr\n",
    "values, times, total = lci_t(list_A=[0, 28.11], list_T=[1, 25], list_D=[1, 100])\n",
    "print('cougar spraying, MJ/ha/yr')\n",
    "#print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')\n",
    "\n",
    "#weed harvning, MJ/ha/yr\n",
    "values, times, total = lci_t(list_A=[0, 843.16], list_T=[1, 25], list_D=[1, 100])\n",
    "print('weed harvning, MJ/ha/yr')\n",
    "#print('times: ', times)\n",
    "print('values: ', values)\n",
    "print('total: ', total)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 42])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([24,32])\n",
    "b = np.array([24,10])\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
